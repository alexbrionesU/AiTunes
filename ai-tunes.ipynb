{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alejandro briones\n",
    "#chris kontsis\n",
    "#sheil patel\n",
    "#cse471 capstone \n",
    "\n",
    "#dev env completed\n",
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r ~/.kaggle\n",
    "!mkdir ~/.kaggle\n",
    "!mv ./kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d geomack/spotifyclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile('spotifyclassification.zip', 'r')\n",
    "zip_ref.extractall('/content')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necesssary data analysis libraries\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "data_frame = pd.read_csv(\"../content/data.csv\")\n",
    "data_frame = data_frame.drop(\"Unnamed: 0\", axis=\"columns\")\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen = [\"energy\", \"liveness\", \"tempo\", \"valence\", \"loudness\", \"speechiness\", \"acousticness\", \"danceability\", \"instrumentalness\"]\n",
    "text1 = data_frame[\"artist\"] + \" - \" + data_frame[\"song_title\"]\n",
    "text2 = text1.values\n",
    "\n",
    "# X = data_frame.drop(droppable, axis=1).values\n",
    "X = data_frame[chosen].values\n",
    "y = data_frame[\"danceability\"].values\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(X)\n",
    "\n",
    "X = pca.transform(X)\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "trace = go.Scatter3d(\n",
    "    x=X[:,0],\n",
    "    y=X[:,1],\n",
    "    z=X[:,2],\n",
    "    text=text2,\n",
    "    mode=\"markers\",\n",
    "    marker=dict(\n",
    "        size=8,\n",
    "        color=y\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[trace])\n",
    "py.iplot(fig, filename=\"test-graph\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen = [\"energy\", \"liveness\", \"tempo\", \"valence\"]\n",
    "text1 = data_frame[\"artist\"] + \" - \" + data_frame[\"song_title\"]\n",
    "text2 = text1.values\n",
    "\n",
    "# X = data_frame.drop(droppable, axis=1).values\n",
    "X = data_frame[chosen].values\n",
    "y = data_frame[\"loudness\"].values\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "\n",
    "X = pca.transform(X)\n",
    "\n",
    "fig = {\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"x\": X[:, 0],\n",
    "            \"y\": X[:, 1],\n",
    "            \"text\": text2,\n",
    "            \"mode\": \"markers\",\n",
    "            \"marker\": {\"size\": 8, \"color\": y}\n",
    "        }\n",
    "    ],\n",
    "    \"layout\": {\n",
    "        \"xaxis\": {\"title\": \"How hard is this to dance to?\"},\n",
    "        \"yaxis\": {\"title\": \"How metal is this?\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "py.iplot(fig, filename=\"test-graph2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elbow test to determine number of clusters for k-means\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "selectedElbowFeatures = data_frame[['acousticness', 'danceability', 'duration_ms','energy','instrumentalness','key','liveness','loudness','speechiness','tempo','valence']]\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(selectedElbowFeatures)\n",
    "\n",
    "wcss = []\n",
    "\n",
    "for i in range(1, 11):\n",
    "    kmeans1 = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    kmeans1.fit(scaled_features)\n",
    "    wcss.append(kmeans1.inertia_)\n",
    "\n",
    "# Plotting the results onto a line graph\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(1, 11), wcss, marker='o', linestyle='--')\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beginning of fitting to model\n",
    "# Kmeans clustering model\n",
    "###Currently removing parameters to see if model performs better removed:'duration_ms'\n",
    "selectedFeatures = data_frame[['acousticness', 'danceability', 'energy','instrumentalness','key','liveness','loudness','speechiness','tempo','valence']]\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(selectedFeatures)\n",
    "\n",
    "kmeans = KMeans(n_clusters = 7)\n",
    "data_frame['cluster'] = kmeans.fit_predict(scaled_features)\n",
    "\n",
    "def recommend_song(mood):\n",
    "\n",
    "  mood_to_cluster = {\n",
    "      'happy':0,\n",
    "      'sad':1,\n",
    "      'enegertic':2,\n",
    "      'anxious':3,\n",
    "      'depression':4,\n",
    "      'calm':5,\n",
    "      'romanctic':6\n",
    "  }\n",
    "\n",
    "  cluster = mood_to_cluster[mood]\n",
    "\n",
    "  song_recommendation = data_frame[data_frame['cluster'] == cluster].sample(1)\n",
    "\n",
    "  return song_recommendation\n",
    "\n",
    "song = recommend_song('anxious')\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K-Distance Graph for DBSCAN Cluster\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "min_samples = 2  # A starting point for min_samples\n",
    "\n",
    "nearest_neighbors = NearestNeighbors(n_neighbors=min_samples)\n",
    "neighbors = nearest_neighbors.fit(scaled_features)\n",
    "distances, indices = neighbors.kneighbors(scaled_features)\n",
    "\n",
    "# Sort the distances\n",
    "sorted_distances = np.sort(distances[:, -1], axis=0)\n",
    "\n",
    "# Plot the k-distance graph\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(sorted_distances)\n",
    "plt.xlabel('Points sorted by distance')\n",
    "plt.ylabel('kth nearest distance')\n",
    "plt.title('k-Distance Graph')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DBSCAN Clustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(eps=0.06, min_samples=2)\n",
    "mood_score_sized = scaled_features_df['mood_score'].values.reshape(-1, 1)\n",
    "data_frame['dbscan_cluster'] = dbscan.fit_predict(mood_score_sized)\n",
    "\n",
    "# Check the number of clusters formed\n",
    "n_clusters_ = len(set(data_frame['dbscan_cluster'])) - (1 if -1 in data_frame['dbscan_cluster'] else 0)\n",
    "n_noise_ = list(data_frame['dbscan_cluster']).count(-1)\n",
    "\n",
    "print(f'Estimated number of clusters: {n_clusters_}')\n",
    "print(f'Estimated number of noise points: {n_noise_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###silhoutte score\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Assuming 'data_frame' is your original DataFrame and it now includes the 'cluster' column from KMeans\n",
    "# Also assuming 'scaled_features_df' is your DataFrame of scaled features with the 'mood_score'\n",
    "\n",
    "# Calculate silhouette score using the mood score and the cluster labels\n",
    "silhouette_avg = silhouette_score(scaled_features_df[['mood_score']], data_frame['cluster'])\n",
    "\n",
    "print(f'The average silhouette score is: {silhouette_avg}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determining qualaites of each cluster\n",
    "cluster_to_mood = {\n",
    "    0: \"energetic\",\n",
    "    1: \"happy\",\n",
    "    2: \"romantic\",\n",
    "    3: \"anxious\",\n",
    "    4: \"depression\",\n",
    "    5: \"sad\",\n",
    "    6: \"calm\",\n",
    "}\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(scaled_features)\n",
    "kmeans = KMeans(n_clusters=7, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "kmeans.fit(principal_components)\n",
    "plt.figure(figsize=(10,5))\n",
    "scatter = plt.scatter(principal_components[:, 0], principal_components[:, 1], c=kmeans.labels_, cmap='rainbow', alpha=0.6)\n",
    "\n",
    "# Add labels for each cluster\n",
    "for i, txt in enumerate(kmeans.labels_):\n",
    "    if txt in cluster_to_mood:\n",
    "      plt.annotate(cluster_to_mood[txt], (principal_components[i, 0], principal_components[i, 1]), fontsize=9, alpha=1.0)\n",
    "    else:\n",
    "      print(f\"Unexpected cluster label: {txt}\")\n",
    "\n",
    "\n",
    "# For better visualization, let's also add a legend\n",
    "legend1 = plt.legend(*scatter.legend_elements(),\n",
    "                    loc=\"upper right\", title=\"Moods\")\n",
    "plt.gca().add_artist(legend1)\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "for cluster_num in range(7):  # Change this if you have a different number of clusters\n",
    "    cluster_songs = data_frame[data_frame['cluster'] == cluster_num]\n",
    "    print(f\"Cluster {cluster_num} ({cluster_to_mood.get(cluster_num, 'Unknown')}):\")\n",
    "    for index, row in cluster_songs.iterrows():\n",
    "        print(f\"{row['artist']} - {row['song_title']}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing linear regression on each cluster\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "clusters = data_frame['cluster'].unique()\n",
    "\n",
    "cluster_models = {}\n",
    "\n",
    "for cluster in clusters:\n",
    "    cluster_data = data_frame[data_frame['cluster'] == cluster]\n",
    "\n",
    "    # Splitting features and target variable\n",
    "    # Assuming 'features' are your song features and 'target' is your target variable\n",
    "    X = cluster_data[['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo' ]]  # Add all your features here\n",
    "    y = cluster_data['valence'].valuess\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    y = y.reshape(-1, 1)\n",
    "    y_scaled = scaler.fit_transform(y)\n",
    "    # Splitting data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Training a linear regression model for this cluster\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Store the trained model\n",
    "    cluster_models[cluster] = model\n",
    "\n",
    "    # Predict & evaluate (optional)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"Cluster {cluster} - MSE: {mse:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_regression_results(y_true, y_pred, model_name):\n",
    "    \"\"\"\n",
    "    Plot regression results: True vs Predicted values and residuals.\n",
    "\n",
    "    y_true: array-like, true target values\n",
    "    y_pred: array-like, predicted target values by the model\n",
    "    model_name: str, name of the regression model\n",
    "    \"\"\"\n",
    "    residuals = y_true - y_pred\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 6))\n",
    "\n",
    "    # Plot true vs predicted values\n",
    "    axes[0].scatter(y_true, y_pred, alpha=0.6)\n",
    "    axes[0].plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'k--', lw=2)\n",
    "    axes[0].set_xlabel('True Value')\n",
    "    axes[0].set_ylabel('Predicted Value')\n",
    "    axes[0].set_title(f'{model_name}: True vs Predicted')\n",
    "\n",
    "    # Plot residuals\n",
    "    axes[1].scatter(y_true, residuals, alpha=0.6)\n",
    "    axes[1].hlines(0, y_true.min(), y_true.max(), 'k', lw=2)\n",
    "    axes[1].set_xlabel('True Value')\n",
    "    axes[1].set_ylabel('Residual')\n",
    "    axes[1].set_title(f'{model_name}: Residuals')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "##plot_regression_results(y, y_pred, cluster[0])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
